import io
import threading
import asyncio
import time
import sounddevice as sd
import soundfile as sf
import edge_tts
import pyautogui
import webbrowser
import os
import tempfile
import speech_recognition as sr
from flask import Flask, request, jsonify
from flask_cors import CORS

# =========================
# FLASK (WEB BRIDGE)
# =========================
app = Flask(__name__)
CORS(app)

# =========================
# VOICE CONFIG
# =========================
VOICE = "en-US-GuyNeural"
RATE = "+0%"
VOLUME = "+100%"
PITCH = "+0Hz"

WAKE_WORDS = ["hey shrion", "shrion", "starra"]

stop_speaking_flag = threading.Event()
is_speaking = False
awake = False

# =========================
# TEXT TO SPEECH
# =========================
def edge_speak(text: str, blocking=False):
    global is_speaking

    if not text.strip():
        return

    finished = threading.Event()

    def _run():
        global is_speaking
        is_speaking = True
        stop_speaking_flag.clear()
        try:
            asyncio.run(_speak_async(text))
        except Exception as e:
            print("TTS ERROR:", e)
        finally:
            time.sleep(0.6)  # prevents mic pickup
            is_speaking = False
            finished.set()

    threading.Thread(target=_run, daemon=True).start()
    if blocking:
        finished.wait()

async def _speak_async(text):
    communicate = edge_tts.Communicate(
        text=text,
        voice=VOICE,
        rate=RATE,
        volume=VOLUME,
        pitch=PITCH,
    )

    audio = io.BytesIO()
    async for chunk in communicate.stream():
        if stop_speaking_flag.is_set():
            return
        if chunk["type"] == "audio":
            audio.write(chunk["data"])

    audio.seek(0)
    data, samplerate = sf.read(audio, dtype="float32")
    channels = 1 if data.ndim == 1 else data.shape[1]

    with sd.OutputStream(samplerate=samplerate, channels=channels) as stream:
        stream.write(data)

def stop_speaking():
    stop_speaking_flag.set()

# =========================
# SPEECH TO TEXT
# =========================
recognizer = sr.Recognizer()

def listen(duration=5):
    if is_speaking:
        return ""

    fs = 16000
    print("Listening...")
    try:
        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype="int16")
        sd.wait()

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            sf.write(tmp.name, recording, fs)
            with sr.AudioFile(tmp.name) as source:
                audio = recognizer.record(source)

        text = recognizer.recognize_google(audio)
        print("You:", text)
        return text.lower()

    except sr.UnknownValueError:
        return ""
    except Exception as e:
        print("Mic error:", e)
        return ""

# =========================
# BRAIN
# =========================
def brain(text):
    global awake

    if not awake:
        if any(w in text for w in WAKE_WORDS):
            awake = True
            edge_speak("I am awake.")
        return

    if "go to sleep" in text:
        awake = False
        edge_speak("Going to sleep.")
        return

    if "exit" in text or "shutdown shrion" in text:
        edge_speak("Shutting down.")
        os._exit(0)

    if "add" in text:
        nums = [int(w) for w in text.split() if w.isdigit()]
        edge_speak(f"The result is {sum(nums)}." if len(nums) >= 2 else "I need two numbers.")
        return

    if "volume up" in text:
        pyautogui.press("volumeup")
        edge_speak("Volume increased.")
    elif "volume down" in text:
        pyautogui.press("volumedown")
        edge_speak("Volume decreased.")
    elif "mute" in text:
        pyautogui.press("volumemute")
        edge_speak("Muted.")
    elif "open notepad" in text:
        os.startfile("notepad.exe")
        edge_speak("Opening Notepad.")
    elif "open calculator" in text:
        os.startfile("calculator.exe")
        edge_speak("Opening Calculator.")
    elif "open youtube" in text:
        webbrowser.open("https://youtube.com")
        edge_speak("Opening YouTube.")
    elif "type" in text:
        pyautogui.write(text.replace("type", "").strip(), interval=0.05)
        edge_speak("Typed.")
    else:
        edge_speak("Command received.")

# =========================
# WEB ENDPOINT
# =========================
@app.route("/speak", methods=["POST"])
def speak_from_web():
    data = request.json or {}
    text = data.get("text", "")
    if text:
        print("WEB:", text)
        brain(text.lower())
        return jsonify({"status": "ok"})
    return jsonify({"status": "empty"})

# =========================
# MAIN
# =========================
if __name__ == "__main__":
    edge_speak("Shrion initialized. Starra is online.")

    threading.Thread(
        target=lambda: app.run(host="0.0.0.0", port=5000, debug=False),
        daemon=True
    ).start()

    while True:
        try:
            command = listen()
            if command:
                brain(command)
        except KeyboardInterrupt:
            stop_speaking()
            break
